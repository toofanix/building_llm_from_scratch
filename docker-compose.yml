services:
  app:
    build: .
    container_name: llm-from-scratch
    working_dir: /workspace
    shm_size: 16g
    env_file:
      - .env.local
    volumes:
      - .:/workspace
    ports:
      - "8888:8888"
      - "6006:6006"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    stdin_open: true
    tty: true
    command: tail -f /dev/null