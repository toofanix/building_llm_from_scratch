{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from utils import GPTModel\n",
    "\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will adopt the `generate_text_simple` function from the previous chapter and introduce 2 new functions.\n",
    "- `text_to_token_ids` and `token_ids_to_text`. These functions will help the conversion between text and token representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from utils import generate_text_simple\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Text: Every effort moves you rentingetic wasnÙ… refres RexAngel infieldcigans\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M['context_length']\n",
    ")\n",
    "\n",
    "print(f\"Output Text: {token_ids_to_text(token_ids, tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The output is gibberish\n",
    "- We will implement a numerical method to evaluate the generated content. This will allow is to monitor and enhance the model's performance throughout the training process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the text generation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUTS:\n",
      " tensor([[16833,  3626,  6100],\n",
      "        [   40,  1107,   588]])\n",
      "OUTPUTS:\n",
      " tensor([[ 3626,  6100,   345],\n",
      "        [ 1107,   588, 11311]])\n"
     ]
    }
   ],
   "source": [
    "# INPUTS\n",
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "inputs = []\n",
    "txt1 = \"every effort moves\"\n",
    "txt2 = \"I really like\"\n",
    "\n",
    "inputs.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "inputs.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "inputs = torch.stack(inputs, dim=0)\n",
    "print(\"INPUTS:\\n\", inputs)\n",
    "\n",
    "\n",
    "#TARGETS\n",
    "targets = []\n",
    "txt1 = \" effort moves you\"\n",
    "txt2 = \" really like chocolate\"\n",
    "\n",
    "targets.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "targets.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "targets = torch.stack(targets, dim=0)\n",
    "print(\"OUTPUTS:\\n\", targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "# Lets get the logits\n",
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "    probas = torch.softmax(logits, dim=-1)\n",
    "    print(probas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOKEN IDS:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"TOKEN IDS:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1:\"\n",
    "      f\" {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.2671e-05, 3.1046e-05, 1.1696e-05])\n",
      "Text 2: tensor([1.0426e-05, 5.4604e-05, 4.7716e-06])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Above are the probabilities of the each input token in the above 2 text examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back propagation\n",
    "- Used to update the model weights\n",
    "- Compute the negative log likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5296, -10.3800, -11.3563, -11.4712,  -9.8154, -12.2528])\n"
     ]
    }
   ],
   "source": [
    "# Calculate log of each token across the entire batch\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.8009)\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average of the log\n",
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.8009)\n"
     ]
    }
   ],
   "source": [
    "# Multiply by negative 1\n",
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This process performed above is known as cross-entropy loss.\n",
    "- Pytorch has an in-built function to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"Logits shape:\", logits.shape)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logits are 3-D (batch_size, number of tokens, vocab-size)\n",
    "- The targets tensor has 2-D (batch_size, number of tokens)\n",
    "- For the cross_entropy we have to flatten by combining them over the batch dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.8009)\n"
     ]
    }
   ],
   "source": [
    "# Using pytorch to calculate the loss\n",
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perplexity\n",
    "- Its a measure that is often used to evaluate the performance of models in tasks like language modeling.\n",
    "- Provides a more interpretable way to understand the uncertainity of model in predicting the next token in a sequence.\n",
    "- Perplexity measures how well the probability distribution predicted by the model matches the actual distribution of words in the dataset. Similar to loss, a lower perplexity indicated that the model predictions are closer to the actual distribution.\n",
    "- It signifies the effective vocabulary size about which the model is uncertain at each step.\n",
    "- This would translate to the model being unsure about which among all the tokens in the vocabulary to generate as the next token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(49064.1641)\n"
     ]
    }
   ],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in the above excercise we have computed the loss and perplexity to 2 inputs. But we will now extend it to the entire training and validation sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the training and validation set losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets first prepare the training and validation datasets.\n",
    "# We will use the same dataset we had used in earlier chapter (\"The Verdict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/chapter2/the-verdict.txt'\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    text_data = file.read()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Characters: 20479\n",
      "Number of Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(f\"Number of Characters: {total_characters}\")\n",
    "print(f\"Number of Tokens: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will split the data in to training and validation sets.\n",
    "- They will be tokenized\n",
    "- Sample will be generated of `context_length`\n",
    "- Samples will be grouped to form batches (with shuffling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.9\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now create the data loader with the datasets we have above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import create_dataloader_v1\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M['context_length'],\n",
    "    stride=GPT_CONFIG_124M['context_length'],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M['context_length'],\n",
    "    stride=GPT_CONFIG_124M['context_length'],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device): # This is only for a batch\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0, 1), target_batch.flatten()\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to compute over all the batches\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.0\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    \n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.987016571892632\n",
      "Validation loss: 10.980592727661133\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "device = \"cpu\"\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(f\"Training loss: {train_loss}\")\n",
    "print(f\"Validation loss: {val_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize list to tack losses and tokens seens\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen , global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):# start main loop\n",
    "        model.train() # ensures/set the model into train mode since there are eval step that happen sometimes\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(model , train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): Train Loss {train_loss:.3f} Val loss {val_loss:0.3f}\")\n",
    "\n",
    "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `evaluate_model` caluclates the losses over the training and validation set while ensuring that the model is in evaluation mode.\n",
    "- This means that gradient checking and dropout are disables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval() # set model in eval mode to turn off dropout.\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train() # set the model back to train mode\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval() # set model in eval mode\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(model=model, idx=encoded, max_new_tokens=50, context_size=context_size)\n",
    "\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    model.train() # set model back in train mode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: We will use `AdamW` as the optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First TRAIN RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "device='cpu'\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "num_epochs = 10\n",
    "start_context = \"Every effort moves you\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train Loss 9.764 Val loss 9.903\n",
      "Ep 1 (Step 000005): Train Loss 8.077 Val loss 8.339\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train Loss 6.760 Val loss 7.044\n",
      "Ep 2 (Step 000015): Train Loss 6.115 Val loss 6.608\n",
      "Every effort moves you, the,,,,,,,,,,.                                     \n",
      "Ep 3 (Step 000020): Train Loss 5.769 Val loss 6.525\n",
      "Ep 3 (Step 000025): Train Loss 5.398 Val loss 6.403\n",
      "Every effort moves you.                                                 \n",
      "Ep 4 (Step 000030): Train Loss 4.753 Val loss 6.312\n",
      "Ep 4 (Step 000035): Train Loss 4.126 Val loss 6.228\n",
      "Every effort moves you, and, and in the picture of the picture, and I had been, and, in the, and, and, and, and of the, and I had been, as of the picture, in the picture--and, and, in\n",
      "Ep 5 (Step 000040): Train Loss 4.001 Val loss 6.200\n",
      "Every effort moves you know it was not that, and in the--I had been.                                    \n",
      "Ep 6 (Step 000045): Train Loss 3.125 Val loss 6.146\n",
      "Ep 6 (Step 000050): Train Loss 2.242 Val loss 6.183\n",
      "Every effort moves you know,\" was one of the Mrs.                                          \n",
      "Ep 7 (Step 000055): Train Loss 1.913 Val loss 6.232\n",
      "Ep 7 (Step 000060): Train Loss 1.472 Val loss 6.283\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with the last word.    \"! The women had been him--it was back the head to look up at the sketch of the donkey.  \"Oh, in\n",
      "Ep 8 (Step 000065): Train Loss 1.088 Val loss 6.337\n",
      "Ep 8 (Step 000070): Train Loss 0.797 Val loss 6.376\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with a laugh: \"Yes--and by me!\"  He laughed again, and threw back his glory, he had dropped his painting, a _jardiniere_ full of\n",
      "Ep 9 (Step 000075): Train Loss 0.501 Val loss 6.416\n",
      "Ep 9 (Step 000080): Train Loss 0.307 Val loss 6.482\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 10 (Step 000085): Train Loss 0.242 Val loss 6.605\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, \n",
    "    train_loader, \n",
    "    val_loader, \n",
    "    optimizer, \n",
    "    device, \n",
    "    num_epochs=num_epochs, \n",
    "    eval_freq=5, \n",
    "    eval_iter=5, \n",
    "    start_context=start_context,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(\n",
    "        epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\"\n",
    "    )\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "build_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
